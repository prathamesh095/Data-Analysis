{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc865320",
   "metadata": {},
   "source": [
    "## **Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   # data manipulation and analysis\n",
    "import numpy as np    # numerical computations\n",
    "import math           # basic mathematical operations\n",
    "\n",
    "import matplotlib.pyplot as plt   # data visualization (static)\n",
    "import seaborn as sns             # statistical visualizations\n",
    "import plotly.express as px       # interactive visualizations\n",
    "import plotly.graph_objects as go # low-level plotly graphing API\n",
    "from plotly.subplots import make_subplots  # multiple plotly subplots\n",
    "import matplotlib.ticker as mticker        # formatting axis ticks\n",
    "\n",
    "from sqlalchemy import create_engine  # database connection\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler  # feature scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aaa02d",
   "metadata": {},
   "source": [
    "### **Data Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c2689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Update file paths to match provided directory and original file names\n",
    "dim_city_path = r'E:\\Projects\\rpc_17_inputs\\rpc_17_inputs\\Datasets\\dim_city.csv'\n",
    "fact_city_readiness_path = r'E:\\Projects\\rpc_17_inputs\\rpc_17_inputs\\Datasets\\fact_city_readiness.csv'\n",
    "fact_print_sales_path = r'E:\\Projects\\rpc_17_inputs\\rpc_17_inputs\\Datasets\\fact_print_sales.csv'\n",
    "fact_ad_revenue_path = r'E:\\Projects\\rpc_17_inputs\\rpc_17_inputs\\Datasets\\fact_ad_revenue.csv'\n",
    "fact_digital_pilot_path = r'E:\\Projects\\rpc_17_inputs\\rpc_17_inputs\\Datasets\\fact_digital_pilot.csv'\n",
    "dim_ad_category_path = r'E:\\Projects\\rpc_17_inputs\\rpc_17_inputs\\Datasets\\dim_ad_category.csv'\n",
    "\n",
    "# Function to generate dummy city data\n",
    "def generate_new_cities(num_new_cities=500):\n",
    "    dim_city = pd.read_csv(dim_city_path)\n",
    "    max_num = int(dim_city['city_id'].str[1:].astype(int).max())\n",
    "    states = ['Uttar Pradesh', 'Delhi', 'Madhya Pradesh', 'Bihar', 'Rajasthan', 'Maharashtra', 'Jharkhand', 'Gujarat']\n",
    "    tiers = ['Tier 1', 'Tier 2', 'Tier 3']\n",
    "    new_cities = []\n",
    "    for i in range(max_num + 1, max_num + num_new_cities + 1):\n",
    "        city_id = f'C{str(i).zfill(3)}'\n",
    "        city = f'City{i}'\n",
    "        state = np.random.choice(states)\n",
    "        tier = np.random.choice(tiers)\n",
    "        new_cities.append({'city_id': city_id, 'city': city, 'state': state.upper(), 'tier': tier})\n",
    "    new_df = pd.DataFrame(new_cities)\n",
    "    updated_dim_city = pd.concat([dim_city, new_df], ignore_index=True)\n",
    "    updated_dim_city.to_csv(dim_city_path, index=False)\n",
    "    return new_cities\n",
    "\n",
    "# Function to update fact_city_readiness with new cities\n",
    "def update_fact_city_readiness(new_cities):\n",
    "    fact_city = pd.read_csv(fact_city_readiness_path)\n",
    "    # Clean up if there's an unnamed index column\n",
    "    if 'Unnamed: 0' in fact_city.columns:\n",
    "        fact_city = fact_city.drop(columns=['Unnamed: 0'])\n",
    "    quarters = []\n",
    "    for year in range(2019, 2025):\n",
    "        for q in range(1, 5):\n",
    "            quarters.append(f'{year}-Q{q}')\n",
    "    new_rows = []\n",
    "    for city in new_cities:\n",
    "        city_id = city['city_id']\n",
    "        tier = city['tier']\n",
    "        # Meaningful ranges based on tier\n",
    "        if tier == 'Tier 1':\n",
    "            lit_mean, smart_mean, int_mean = 85, 75, 70\n",
    "        elif tier == 'Tier 2':\n",
    "            lit_mean, smart_mean, int_mean = 80, 70, 65\n",
    "        else:\n",
    "            lit_mean, smart_mean, int_mean = 70, 65, 55\n",
    "        for quarter in quarters:\n",
    "            literacy_rate = round(np.random.normal(lit_mean, 2), 2)\n",
    "            smartphone_penetration = round(np.random.normal(smart_mean, 2), 2)\n",
    "            internet_penetration = round(np.random.normal(int_mean, 2), 2)\n",
    "            # Ensure values are reasonable (0-100)\n",
    "            literacy_rate = max(0, min(100, literacy_rate))\n",
    "            smartphone_penetration = max(0, min(100, smartphone_penetration))\n",
    "            internet_penetration = max(0, min(100, internet_penetration))\n",
    "            new_rows.append({\n",
    "                'city_id': city_id,\n",
    "                'quarter': quarter,\n",
    "                'literacy_rate': literacy_rate,\n",
    "                'smartphone_penetration': smartphone_penetration,\n",
    "                'internet_penetration': internet_penetration\n",
    "            })\n",
    "    new_fact_df = pd.DataFrame(new_rows)\n",
    "    updated_fact_city = pd.concat([fact_city, new_fact_df], ignore_index=True)\n",
    "    updated_fact_city.to_csv(fact_city_readiness_path, index=True)  # Save with index as per original\n",
    "\n",
    "# Function to generate months\n",
    "def generate_months():\n",
    "    months = []\n",
    "    start_date = datetime(2019, 1, 1)\n",
    "    for i in range(72):  # 6 years * 12 months\n",
    "        month_date = start_date + timedelta(days=31 * i)  # Approximate\n",
    "        months.append(month_date.strftime('%Y-%m-%d 00:00:00'))\n",
    "    return months\n",
    "\n",
    "# Function to update fact_print_sales with new cities/editions\n",
    "def update_fact_print_sales(new_cities):\n",
    "    fact_print = pd.read_csv(fact_print_sales_path)\n",
    "    months = generate_months()\n",
    "    new_rows = []\n",
    "    for city in new_cities:\n",
    "        city_id = city['city_id']\n",
    "        edition_id = f'ED1{city_id[1:]}'\n",
    "        state = city['state']\n",
    "        language = 'English' if state in ['DELHI', 'MAHARASHTRA'] else 'Hindi'\n",
    "        for month in months:\n",
    "            copies_sold = int(np.random.normal(300000, 50000))\n",
    "            copies_returned = int(np.random.normal(15000, 5000))\n",
    "            net_circulation = copies_sold - copies_returned\n",
    "            # Ensure positive\n",
    "            copies_sold = max(100000, copies_sold)\n",
    "            copies_returned = max(5000, min(copies_returned, copies_sold - 10000))\n",
    "            net_circulation = copies_sold - copies_returned\n",
    "            new_rows.append({\n",
    "                'edition_ID': edition_id,\n",
    "                'City_ID': city_id,\n",
    "                'Language': language,\n",
    "                'State': state,\n",
    "                'Month': month,\n",
    "                'Copies Sold': copies_sold,\n",
    "                'copies_returned': copies_returned,\n",
    "                'Net_Circulation': net_circulation\n",
    "            })\n",
    "    new_fact_df = pd.DataFrame(new_rows)\n",
    "    updated_fact_print = pd.concat([fact_print, new_fact_df], ignore_index=True)\n",
    "    # Clean any invalid characters in existing data (like â‚¹)\n",
    "    updated_fact_print['Copies Sold'] = updated_fact_print['Copies Sold'].apply(lambda x: int(str(x).replace('â‚¹', '')) if isinstance(x, str) and 'â‚¹' in x else x)\n",
    "    updated_fact_print.to_csv(fact_print_sales_path, index=False)\n",
    "\n",
    "# Function to update fact_ad_revenue with new editions\n",
    "def update_fact_ad_revenue(new_cities):\n",
    "    fact_ad = pd.read_csv(fact_ad_revenue_path)\n",
    "    dim_ad = pd.read_csv(dim_ad_category_path)  # To get categories\n",
    "    ad_categories = dim_ad['ad_category_id'].tolist()\n",
    "    quarters = [f'{year}-Q{q}' for year in range(2019, 2025) for q in range(1, 5)]\n",
    "    currencies = ['INR', 'USD', 'EUR']\n",
    "    comments = ['', 'Festive push', 'New FMCG client onboarded', 'Real estate slowdown', 'Seasonal drop in demand', 'Govt. reduced ad spend', 'Price hike concern']\n",
    "    new_rows = []\n",
    "    for city in new_cities:\n",
    "        edition_id = f'ED1{city['city_id'][1:]}'\n",
    "        for ad_cat in ad_categories:\n",
    "            for quarter in quarters:\n",
    "                ad_revenue = round(np.random.normal(3000000, 1000000), 2)\n",
    "                ad_revenue = max(100000, ad_revenue)\n",
    "                currency = np.random.choice(currencies)\n",
    "                comment = np.random.choice(comments)\n",
    "                new_rows.append({\n",
    "                    'edition_id': edition_id,\n",
    "                    'ad_category': ad_cat,\n",
    "                    'quarter': quarter,\n",
    "                    'ad_revenue': ad_revenue,\n",
    "                    'currency': currency,\n",
    "                    'comments': comment\n",
    "                })\n",
    "    new_fact_df = pd.DataFrame(new_rows)\n",
    "    updated_fact_ad = pd.concat([fact_ad, new_fact_df], ignore_index=True)\n",
    "    # Standardize quarter formats in existing data\n",
    "    updated_fact_ad['quarter'] = updated_fact_ad['quarter'].str.replace('Q', '-Q').str.replace('th Qtr ', '-Q').str.replace('1st', '1').str.replace('2nd', '2').str.replace('3rd', '3').str.replace('4th', '4')\n",
    "    updated_fact_ad['currency'] = updated_fact_ad['currency'].str.replace('IN RUPEES', 'INR')\n",
    "    updated_fact_ad.to_csv(fact_ad_revenue_path, index=False)\n",
    "\n",
    "# Function to update fact_digital_pilot with new cities\n",
    "def update_fact_digital_pilot(new_cities):\n",
    "    fact_digital = pd.read_csv(fact_digital_pilot_path)\n",
    "    if 'Unnamed: 0' in fact_digital.columns:\n",
    "        fact_digital = fact_digital.drop(columns=['Unnamed: 0'])\n",
    "    platforms = fact_digital['platform'].unique().tolist()\n",
    "    ad_categories = ['A001', 'A002', 'A003', 'A004']\n",
    "    months = [f'2021-{str(m).zfill(2)}' for m in range(1, 13)]\n",
    "    feedbacks = fact_digital['cumulative_feedback_from_customers'].unique().tolist()\n",
    "    new_rows = []\n",
    "    for city in new_cities:\n",
    "        for platform in platforms:\n",
    "            for month in months:\n",
    "                dev_cost = int(np.random.normal(200000, 50000))\n",
    "                marketing_cost = int(np.random.normal(70000, 20000))\n",
    "                users_reached = int(np.random.normal(25000, 10000))\n",
    "                downloads_or_accesses = int(np.random.normal(15000, 5000))\n",
    "                avg_bounce_rate = round(np.random.normal(65, 15), 2)\n",
    "                feedback = np.random.choice(feedbacks)\n",
    "                ad_cat = np.random.choice(ad_categories)\n",
    "                new_rows.append({\n",
    "                    'platform': platform,\n",
    "                    'launch_month': month,\n",
    "                    'ad_category_id': ad_cat,\n",
    "                    'dev_cost': dev_cost,\n",
    "                    'marketing_cost': marketing_cost,\n",
    "                    'users_reached': users_reached,\n",
    "                    'downloads_or_accesses': downloads_or_accesses,\n",
    "                    'avg_bounce_rate': avg_bounce_rate,\n",
    "                    'cumulative_feedback_from_customers': feedback,\n",
    "                    'city_id': city['city_id']\n",
    "                })\n",
    "    new_fact_df = pd.DataFrame(new_rows)\n",
    "    updated_fact_digital = pd.concat([fact_digital, new_fact_df], ignore_index=True)\n",
    "    updated_fact_digital.to_csv(fact_digital_pilot_path, index=True)\n",
    "\n",
    "# Run updates\n",
    "new_cities = generate_new_cities(500)  # Adds 500 new cities, resulting in >10k new entries across fact tables\n",
    "update_fact_city_readiness(new_cities)\n",
    "update_fact_print_sales(new_cities)\n",
    "update_fact_ad_revenue(new_cities)\n",
    "update_fact_digital_pilot(new_cities)\n",
    "\n",
    "print(\"All files updated with meaningful dummy data at E:\\\\Projects\\\\rpc_17_inputs\\\\rpc_17_inputs\\\\Datasets\\\\. Total new entries exceed 10k across the datasets.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a71f01",
   "metadata": {},
   "source": [
    "## **Loading the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2fd1db",
   "metadata": {},
   "source": [
    "## **Connecting to the DataBase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75353f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# Encode the password\n",
    "password = quote_plus(\"USE_YOUR_PASSWORD\")\n",
    "db_name = \"legacy_newspaper\"\n",
    "\n",
    "connection_string = f\"mysql+pymysql://root:{password}@localhost:3306/{db_name}\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Test\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT DATABASE();\"))\n",
    "    print(\"Connected to:\", result.scalar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa32538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"show tables;\" , engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2629b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: read all tables\n",
    "df = pd.read_sql(\"SHOW TABLES;\", engine)\n",
    "list_of_tables = df.iloc[:, 0].tolist()  # Extract table names from the first column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e01362",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ad_category_df     = pd.read_sql(\"select * from dim_ad_category;\" , engine)\n",
    "dim_city_df            = pd.read_sql(\"select * from dim_city;\" , engine)\n",
    "fact_ad_revenue_df     = pd.read_sql(\"select * from fact_ad_revenue;\" , engine)\n",
    "fact_city_readiness_df = pd.read_sql(\"select * from fact_city_readiness;\" , engine)\n",
    "fact_digital_pilot_df  = pd.read_sql(\"select * from fact_digital_pilot;\" , engine)\n",
    "fact_print_sales_df    = pd.read_sql(\"select * from fact_print_sales;\" , engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f8d59",
   "metadata": {},
   "source": [
    "## **Preprocessing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_print_sales_df.rename(columns={'Month': 'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed0d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ad_category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21586a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_city_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591dbecf",
   "metadata": {},
   "source": [
    "### **Standardizing the Quarter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_quarter(quarter_str):\n",
    "    # Case 1: Format 'YYYY--Q#' (e.g., '2023--Q2' -> '2023-Q2')\n",
    "    if quarter_str[:4].isdigit():\n",
    "        parts = quarter_str.split('--')\n",
    "        if len(parts) == 2:\n",
    "            return f\"{parts[0]}-{parts[1]}\"\n",
    "    \n",
    "    # Case 2: Format '# -Qtr YYYY' (e.g., '4 -Qtr 2020' -> '2020-Q4')\n",
    "    if 'Qtr' in quarter_str:\n",
    "        parts = quarter_str.split(' ')\n",
    "        if len(parts) == 3:\n",
    "            return f\"{parts[2]}-Q{parts[0]}\"\n",
    "    \n",
    "    # Case 3: Format '-Q#-YYYY' (e.g., '-Q1-2019' -> '2019-Q1')\n",
    "    if quarter_str[:2] == '-Q':\n",
    "        parts = quarter_str.split('-')\n",
    "        if len(parts) == 3:\n",
    "            return f\"{parts[2]}-{parts[1]}\"\n",
    "    \n",
    "    # Return original if no match (for debugging or unexpected formats)\n",
    "    return quarter_str\n",
    "\n",
    "\n",
    "fact_ad_revenue_df['quarter'] = fact_ad_revenue_df['quarter'].apply(standardize_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_ad_revenue_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_city_readiness_df.drop(columns=['MyUnknownColumn'] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8938be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_city_readiness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20008f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_digital_pilot_df.drop(columns=['MyUnknownColumn'] , inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53371e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_digital_pilot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_print_sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_print_sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75adb85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_formatter = lambda x: f\"{parts[0]}-{parts[1]}-{parts[2]}\" if len(parts := (x[:-8].split('-'))) == 3 else f\"{parts[0]}-{parts[1]}-01\" if len(parts) == 2 else f\"{parts[0]}-01-01\"\n",
    "fact_print_sales_df['date'] = fact_print_sales_df['date'].apply(date_formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_print_sales_df = fact_print_sales_df[fact_print_sales_df['date'] != '-01-01']\n",
    "fact_print_sales_df['date'] = pd.to_datetime(fact_print_sales_df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7eea15",
   "metadata": {},
   "source": [
    "## **Primary Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b603f1",
   "metadata": {},
   "source": [
    "#### **1. Print Circulation Trends**\n",
    "\n",
    "Based on the aggregated data from fact_print_sales.csv, the trend in copies printed \n",
    "(calculated as Copies Sold + copies_returned), copies sold, and net circulation across all \n",
    "cities from 2019 to 2024 shows an overall decline. Here's the year-wise summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6944a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_summary = fact_print_sales_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dbe912",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_summary['Year'] = yearly_summary['date'].dt.year\n",
    "yearly_summary['Copies Printed'] = yearly_summary['Copies Sold'] + yearly_summary['copies_returned']\n",
    "\n",
    "yearly_summary = yearly_summary.groupby('Year').agg({\n",
    "    'Copies Printed': 'sum',\n",
    "    'Copies Sold': 'sum',\n",
    "    'Net_Circulation': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "yearly_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure integers\n",
    "yearly_summary['Copies Printed'] = yearly_summary['Copies Printed'].astype(int)\n",
    "yearly_summary['Copies Sold'] = yearly_summary['Copies Sold'].astype(int)\n",
    "yearly_summary['Net_Circulation'] = yearly_summary['Net_Circulation'].astype(int)\n",
    "\n",
    "# Plotting the yearly print circulation trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(yearly_summary['Year'], yearly_summary['Copies Printed'], \n",
    "         label='Copies Printed', marker='o', linewidth=2)\n",
    "plt.plot(yearly_summary['Year'], yearly_summary['Copies Sold'], \n",
    "         label='Copies Sold', marker='s', linewidth=2)\n",
    "plt.plot(yearly_summary['Year'], yearly_summary['Net_Circulation'], \n",
    "         label='Net Circulation', marker='^', linewidth=2)\n",
    "\n",
    "# Formatting the plot\n",
    "plt.title('Print Circulation Trends (2019 - 2024)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Number of Copies', fontsize=12)\n",
    "plt.legend(title=\"Metrics\", fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xticks(yearly_summary['Year'])\n",
    "\n",
    "# Format Y-axis to show integers with commas\n",
    "plt.gca().yaxis.set_major_formatter(mticker.StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4741db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YoY Growth = (Current - Previous) / Previous * 100\n",
    "yearly_summary['YoY_Copies_Printed'] = yearly_summary['Copies Printed'].pct_change() * 100\n",
    "yearly_summary['YoY_Copies_Sold'] = yearly_summary['Copies Sold'].pct_change() * 100\n",
    "yearly_summary['YoY_Net_Circulation'] = yearly_summary['Net_Circulation'].pct_change() * 100\n",
    "\n",
    "\n",
    "\n",
    "yearly_summary['YoY_Copies_Printed'] = (\n",
    "    (yearly_summary['Copies Printed'] - yearly_summary['Copies Printed'].shift(1)) \n",
    "    / yearly_summary['Copies Printed'].shift(1) * 100\n",
    ")\n",
    "\n",
    "yearly_summary['YOY_Copies_Sold'] = (\n",
    "    (yearly_summary['Copies Sold'] - yearly_summary['Copies Sold'].shift(1))\n",
    "    / yearly_summary['Copies Sold'].shift(1) * 100\n",
    ")\n",
    "\n",
    "yearly_summary['YOY_Net_Circulation'] = (\n",
    "    (yearly_summary['Net_Circulation'] - yearly_summary['Net_Circulation'].shift(1))\n",
    "    /yearly_summary['Net_Circulation'].shift(1) * 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green gradient for Copies, red-blue for YoY\n",
    "yearly_summary.style.background_gradient(subset=['Copies Printed', 'Copies Sold', 'Net_Circulation'], cmap=\"Greens\") \\\n",
    "               .background_gradient(subset=['YoY_Copies_Printed', 'YoY_Copies_Sold', 'YoY_Net_Circulation'], cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10bd00f",
   "metadata": {},
   "source": [
    "#### **2. Top Performing Cities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18139d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_city_summary = fact_print_sales_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_city_summary['Total Printed'] = yearly_city_summary['Copies Sold'] + yearly_city_summary['copies_returned']\n",
    "required_cols =['city','state','date','Total Printed','Copies Sold','Net_Circulation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3efe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames\n",
    "merged_df = pd.merge(\n",
    "    left=dim_city_df,\n",
    "    right=yearly_city_summary,\n",
    "    left_on='city_id',\n",
    "    right_on='City_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Select required columns and create a copy to avoid SettingWithCopyWarning\n",
    "yearly_city_summary = merged_df[required_cols].copy()\n",
    "yearly_city_summary['date'] = yearly_city_summary['date'].dt.year\n",
    "\n",
    "# Aggregate by year and city\n",
    "yearly_city_summary = yearly_city_summary.groupby(['date', 'city']).agg({\n",
    "    'Total Printed': 'sum',\n",
    "    'Copies Sold': 'sum',\n",
    "    'Net_Circulation': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Sort by date and Net_Circulation descending within each date\n",
    "sorted_df = yearly_city_summary.sort_values(['date', 'Net_Circulation'], ascending=[True, False])\n",
    "\n",
    "# Group by date and take head(2)\n",
    "result = sorted_df.groupby('date', group_keys=False).head(2)[['date', 'city', 'Net_Circulation']].reset_index(drop=True)\n",
    "\n",
    "# Display result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb8255",
   "metadata": {},
   "source": [
    "#### **3. Print Waste Analysis**\n",
    "Which cities have the largest gap between copies printed and net circulation, and \n",
    "how has that gap changed over time? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ed5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_waste_data = yearly_city_summary.copy()\n",
    "\n",
    "print_waste_data['print_waste'] = yearly_city_summary['Total Printed'] - yearly_city_summary['Net_Circulation']\n",
    "print_waste_data_df = print_waste_data[['city' , 'print_waste']]\n",
    "\n",
    "print_waste_data_City_df = print_waste_data_df.groupby('city')['print_waste'].sum().reset_index().sort_values(by='print_waste' , ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02feb83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_waste_data_City_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6bf034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced bar chart\n",
    "fig = px.bar(\n",
    "    print_waste_data_City_df.head(100),\n",
    "    x='city',\n",
    "    y='print_waste',\n",
    "    title='Print Waste by City (2019–2025)',\n",
    "    color='print_waste',  # Color bars based on value for better visual distinction\n",
    "    color_continuous_scale='Burg',  # Nice color gradient\n",
    "    hover_data={'city': True, 'print_waste': True},  # Add hover info\n",
    "    labels={'print_waste': 'Print Waste (units)', 'city': 'City'}  # Axis labels\n",
    ")\n",
    "\n",
    "# Update layout for aesthetics\n",
    "fig.update_layout(\n",
    "    title_font_size=24,\n",
    "    title_x=0.5,  # Center the title\n",
    "    xaxis_tickangle=-45,  # Rotate x-axis labels for readability\n",
    "    yaxis=dict(title='Print Waste (Units)'),\n",
    "    template='plotly_white',  # Clean background\n",
    "    coloraxis_colorbar=dict(title='Print Waste')  # Color bar title\n",
    ")\n",
    "\n",
    "# Optional: sort cities by print_waste\n",
    "fig.update_xaxes(categoryorder='total descending')\n",
    "\n",
    "# Show the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7a62b",
   "metadata": {},
   "source": [
    "#### **4. Ad Revenue Trends by Category**\n",
    "How has ad revenue evolved across different ad categories between 2019 and \n",
    "2024? Which categories have remained strong, and which have declined? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d541383",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_revenue = fact_ad_revenue_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7704f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_revenue['ad_revenue_inr'] = cat_revenue['ad_revenue']  # default\n",
    "cat_revenue.loc[fact_ad_revenue_df['currency']=='EUR', 'ad_revenue_inr'] *= 104.19\n",
    "cat_revenue.loc[cat_revenue['currency']=='USD', 'ad_revenue_inr'] *= 88.68\n",
    "\n",
    "cat_revenue['ad_revenue_inr'] = cat_revenue['ad_revenue_inr'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_revenue['Year'] = cat_revenue['quarter'].str.split('-').str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16bd812",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ad_category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a6f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_revenue_yearly = cat_revenue.groupby(['Year','ad_category'])['ad_revenue'].sum().reset_index()\n",
    "cat_revenue_yearly = pd.merge(\n",
    "    left=cat_revenue_yearly,\n",
    "    right=dim_ad_category_df,\n",
    "    left_on='ad_category',\n",
    "    right_on='ad_category_id'\n",
    ").reset_index()\n",
    "\n",
    "cols_req = ['Year' , 'standard_ad_category' , 'ad_revenue']\n",
    "cat_revenue_yearly = cat_revenue_yearly[cols_req]\n",
    "\n",
    "cat_revenue_in_million =round(cat_revenue_yearly['ad_revenue'] / 1000000 , 2)\n",
    "cat_revenue_yearly['ad_revenue_in_million'] = cat_revenue_in_million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom colors for each category\n",
    "color_map = {\n",
    "    'Government': '#FF4C4C',  # Red\n",
    "    'FMCG': '#4CAF50',        # Green\n",
    "    'Real Estate': '#2196F3', # Blue\n",
    "    'Automobile': '#FFC107'   # Yellow\n",
    "}\n",
    "\n",
    "# Create the line plot using Plotly Express\n",
    "fig = px.line(\n",
    "    cat_revenue_yearly,\n",
    "    x='Year',\n",
    "    y='ad_revenue_in_million',\n",
    "    color='standard_ad_category',\n",
    "    title='Ad Revenue by Category (2019–2024)',\n",
    "    labels={\n",
    "        'Year': 'Year',\n",
    "        'ad_revenue_in_million': 'Ad Revenue (in Millions)',\n",
    "        'standard_ad_category': 'Category'\n",
    "    },\n",
    "    color_discrete_map=color_map,\n",
    "    markers=True  # Add markers to each data point\n",
    ")\n",
    "\n",
    "# Customize the layout for an amazing look\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=500,\n",
    "    title={\n",
    "        'text': 'Ad Revenue by Category (2019–2024)',\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 20, 'family': 'Arial', 'color': '#333'}\n",
    "    },\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Ad Revenue (in Millions)',\n",
    "    xaxis={\n",
    "        'tickvals': [2019, 2020, 2021, 2022, 2023, 2024],\n",
    "        'ticktext': ['2019', '2020', '2021', '2022', '2023', '2024'],\n",
    "        'title_font': {'size': 14},\n",
    "        'tickfont': {'size': 12}\n",
    "    },\n",
    "    yaxis={\n",
    "        'title_font': {'size': 14},\n",
    "        'tickfont': {'size': 12}\n",
    "    },\n",
    "    legend={\n",
    "        'title': 'Category',\n",
    "        'font': {'size': 12},\n",
    "        'x': 1.02,\n",
    "        'y': 0.5,\n",
    "        'xanchor': 'left',\n",
    "        'yanchor': 'middle'\n",
    "    },\n",
    "    plot_bgcolor='rgba(245, 245, 245, 1)',  # Light background\n",
    "    paper_bgcolor='rgba(255, 255, 255, 1)', # White paper background\n",
    "    hovermode='x unified',  # Unified hover tooltip for all lines\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Customize line and marker styles\n",
    "fig.update_traces(\n",
    "    line=dict(width=2.5),\n",
    "    marker=dict(size=8, line=dict(width=1, color='DarkSlateGrey')),\n",
    "    mode='lines+markers'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de14c5",
   "metadata": {},
   "source": [
    "#### **5. City-Level Ad Revenue Performance** \n",
    "Which cities generated the most ad revenue, and how does that correlate with \n",
    "their print circulation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23a10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_revenue = (\n",
    "    pd.merge(cat_revenue, fact_print_sales_df, left_on='edition_id', right_on='edition_ID')\n",
    "      [['City_ID', 'date', 'Net_Circulation', 'ad_revenue_inr']]\n",
    "      .merge(dim_city_df, left_on='City_ID', right_on='city_id')\n",
    "      [['city', 'Net_Circulation', 'ad_revenue_inr']]\n",
    "      .groupby('city', as_index=False)[['Net_Circulation', 'ad_revenue_inr']]\n",
    "      .sum()\n",
    ")\n",
    "\n",
    "city_revenue = city_revenue.sort_values(by='ad_revenue_inr' , ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert INR values to trillions for readability\n",
    "city_revenue['ad_revenue_inr_trillion'] = round(city_revenue['ad_revenue_inr'] / 1e12 , 2)\n",
    "\n",
    "# Create bar chart\n",
    "fig = px.bar(\n",
    "    city_revenue.sort_values('ad_revenue_inr', ascending=False).head(20),  # top 20 cities\n",
    "    x='city',\n",
    "    y='ad_revenue_inr_trillion',\n",
    "    title='Top 20 Cities by Ad Revenue (in Trillions INR)',\n",
    "    text='ad_revenue_inr_trillion',\n",
    "    color='ad_revenue_inr_trillion',\n",
    "    color_continuous_scale='Viridis',\n",
    "    hover_data={'ad_revenue_inr': ':,', 'ad_revenue_inr_trillion': ':.2f'}  # formatted hover info\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_font_size=22,\n",
    "    title_x=0.5,  # center title\n",
    "    xaxis_tickangle=-45,\n",
    "    yaxis_title='Ad Revenue (Trillions INR)',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f5e5d",
   "metadata": {},
   "source": [
    "**Co-relation Between ad revenue and the net circulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = city_revenue[['Net_Circulation', 'ad_revenue_inr']].corr().loc['Net_Circulation', 'ad_revenue_inr']\n",
    "print(f\"Correlation between Net Circulation and Ad Revenue: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a622a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    city_revenue,\n",
    "    x='ad_revenue_inr',\n",
    "    y='Net_Circulation', \n",
    "    trendline='ols',  # Adds a linear regression trendline\n",
    "    title='Ad Revenue vs Net Circulation by City',\n",
    "    labels={\n",
    "        'ad_revenue_inr': 'Ad Revenue (INR)',\n",
    "        'Net_Circulation': 'Net Circulation'\n",
    "    },\n",
    "    template='plotly_white'  # Clean visual theme\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=10, color='royalblue', line=dict(width=1, color='DarkSlateGrey')))\n",
    "fig.update_layout(title_font_size=20, title_x=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021de06",
   "metadata": {},
   "source": [
    " **6. Digital Readiness vs. Performance**\n",
    "  Which cities show high digital readiness (based on smartphone, internet, and \n",
    "    literacy rates) but had low digital pilot engagement? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffbe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "readiness_agg = fact_city_readiness_df.groupby('city_id').agg({\n",
    "    'literacy_rate' : 'mean',\n",
    "    'smartphone_penetration' : 'mean',\n",
    "    'internet_penetration' : 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "readiness_metrics = ['literacy_rate', 'smartphone_penetration', 'internet_penetration']\n",
    "readiness_agg[readiness_metrics] = scaler.fit_transform(readiness_agg[readiness_metrics])\n",
    "readiness_agg['readiness_score'] = readiness_agg[readiness_metrics].mean(axis=1)\n",
    "\n",
    "engagement_agg = fact_digital_pilot_df.groupby('city_id').agg({\n",
    "    'users_reached' : 'sum',\n",
    "    'downloads_or_accesses' : 'sum',\n",
    "    'avg_bounce_rate' : 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "engagement_matrics =['users_reached' , 'downloads_or_accesses' , 'avg_bounce_rate']\n",
    "engagement_agg[engagement_matrics] = scaler.fit_transform(engagement_agg[engagement_matrics])\n",
    "engagement_agg['inverted_bounce_rate'] = 1 - engagement_agg['avg_bounce_rate']\n",
    "\n",
    "engagement_agg['engagement_score'] =(\n",
    "    (engagement_agg['avg_bounce_rate'] + engagement_agg['downloads_or_accesses'] + engagement_agg['users_reached'])\n",
    "    / 3\n",
    ")\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    readiness_agg[['city_id', 'readiness_score']],\n",
    "    engagement_agg[['city_id', 'engagement_score']],\n",
    "    on='city_id',\n",
    "    how='inner'  # Only keep cities present in both datasets\n",
    ")\n",
    "\n",
    "readiness_threshold  = merged_df['readiness_score'].quantile(0.75) #top 25%\n",
    "engagement_threshold = merged_df['engagement_score'].quantile(0.25) #bottom 25% \n",
    "\n",
    "target_cities = merged_df[\n",
    "    (merged_df['readiness_score'] >= readiness_threshold) &\n",
    "    (merged_df['engagement_score'] <= engagement_threshold)\n",
    "][['city_id', 'readiness_score', 'engagement_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d78781",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cities = pd.merge(\n",
    "    left=dim_city_df,\n",
    "    right=target_cities,\n",
    "    on='city_id',\n",
    "    how='inner'\n",
    ")[['city', 'readiness_score', 'engagement_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25777d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c385ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort the DataFrame by readiness_score descending (to order cities by high readiness)\n",
    "target_cities_sorted = target_cities.sort_values('readiness_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create the line plot using Plotly Graph Objects\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add line for readiness_score (high values, e.g., green line)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=target_cities_sorted['city'],\n",
    "        y=target_cities_sorted['readiness_score'],\n",
    "        mode='lines+markers',  # Lines connecting points with markers\n",
    "        name='Readiness Score',\n",
    "        line=dict(color='green', width=3),\n",
    "        marker=dict(size=8, color='green'),\n",
    "        hovertemplate='<b>%{x}</b><br>Readiness Score: %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add line for engagement_score (low values, e.g., red line)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=target_cities_sorted['city'],\n",
    "        y=target_cities_sorted['engagement_score'],\n",
    "        mode='lines+markers',\n",
    "        name='Engagement Score',\n",
    "        line=dict(color='red', width=3, dash='dash'),  # Dashed for distinction\n",
    "        marker=dict(size=8, color='red'),\n",
    "        hovertemplate='<b>%{x}</b><br>Engagement Score: %{y:.3f}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 3: Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': 'High Digital Readiness vs. Low Digital Pilot Engagement by City',\n",
    "        'x': 0.5,  # Center the title\n",
    "        'xanchor': 'center',\n",
    "        'font': {'size': 16}\n",
    "    },\n",
    "    xaxis_title='City (Sorted by Descending Readiness Score)',\n",
    "    yaxis_title='Normalized Score (0-1)',\n",
    "    hovermode='x unified',  # Unified hover for both lines\n",
    "    legend=dict(\n",
    "        x=0.01,\n",
    "        y=0.99,\n",
    "        bgcolor='rgba(255,255,255,0.8)',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    ),\n",
    "    plot_bgcolor='rgba(240,240,240,0.5)',  # Light background\n",
    "    width=1000,  # Adjust width for better readability\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Rotate x-axis labels for long city names (if needed)\n",
    "fig.update_xaxes(tickangle=45)\n",
    "\n",
    "# Step 4: Show the plot (interactive in Jupyter/Colab, or browser)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sort by readiness_score to create a sequence for the line plot\n",
    "target_cities_sorted = target_cities.sort_values('readiness_score').reset_index(drop=True)\n",
    "\n",
    "# Step 2: Create the line plot using plotly.express\n",
    "fig = px.line(\n",
    "    data_frame=target_cities_sorted,\n",
    "    x='readiness_score',\n",
    "    y='engagement_score',\n",
    "    markers=True,  # Add markers at data points for clarity\n",
    "    title='Digital Readiness vs. Engagement for Target Cities',\n",
    "    labels={\n",
    "        'readiness_score': 'Digital Readiness Score',\n",
    "        'engagement_score': 'Digital Engagement Score',\n",
    "        'city': 'City'\n",
    "    },\n",
    "    hover_data=['city'],  # Show city name on hover\n",
    "    text='city'  # Optionally label points with city names (if few cities)\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "fig.update_traces(\n",
    "    textposition='top center',  # Position of city labels\n",
    "    mode='lines+markers+text'  # Include lines, markers, and text labels\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title='Digital Readiness Score',\n",
    "    yaxis_title='Digital Engagement Score',\n",
    "    showlegend=False,  # No legend needed for single line\n",
    "    hovermode='closest'  # Better hover interaction\n",
    ")\n",
    "\n",
    "# Step 3: Display the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f3946",
   "metadata": {},
   "source": [
    "#### **7. Ad Revenue vs. Circulation ROI**\n",
    "Which cities had the highest ad revenue per net circulated copy? Is this ratio \n",
    "improving or worsening over time? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acda465",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_per_net_circulation = city_revenue.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_per_net_circulation['revenue_per_net_circulation'] = round(revenue_per_net_circulation['ad_revenue_inr'] / revenue_per_net_circulation['Net_Circulation'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240107df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart\n",
    "fig = px.bar(\n",
    "    revenue_per_net_circulation.sort_values('revenue_per_net_circulation', ascending=False).head(20),  # top 20 cities\n",
    "    x='city',\n",
    "    y='revenue_per_net_circulation',\n",
    "    title='Top 20 Cities by Ad Revenue Per Unit Circulation (IN INR))',\n",
    "    text='revenue_per_net_circulation',\n",
    "    color='revenue_per_net_circulation',\n",
    "    color_continuous_scale='Viridis',\n",
    "    hover_data={'Net_Circulation': ':,', 'revenue_per_net_circulation': ':.2f'}  # formatted hover info\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_font_size=22,\n",
    "    title_x=0.5,  # center title\n",
    "    xaxis_tickangle=-45,\n",
    "    yaxis_title='Ad Revenue Per unit Net Circulation (INR)',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98951b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_revenue = (\n",
    "    pd.merge(cat_revenue, fact_print_sales_df, left_on='edition_id', right_on='edition_ID')\n",
    "      [['City_ID', 'date', 'Net_Circulation', 'ad_revenue_inr']]\n",
    "      .merge(dim_city_df, left_on='City_ID', right_on='city_id')\n",
    "      [['date','city', 'Net_Circulation', 'ad_revenue_inr']]\n",
    ")\n",
    "\n",
    "# Convert to year\n",
    "city_revenue['date'] = city_revenue['date'].dt.year\n",
    "\n",
    "# Aggregate city + year\n",
    "city_revenue = (\n",
    "    city_revenue.groupby(['city','date'], as_index=False)\n",
    "                .agg({'ad_revenue_inr':'sum','Net_Circulation':'sum'})\n",
    "                .sort_values(['city','date'])\n",
    ")\n",
    "\n",
    "# Revenue per net circulation\n",
    "city_revenue['revenue_per_net_circulation'] = (\n",
    "    city_revenue['ad_revenue_inr'] / city_revenue['Net_Circulation']\n",
    ").round(2)\n",
    "\n",
    "# YoY % change (by city)\n",
    "city_revenue['YOY'] = (\n",
    "    city_revenue.groupby('city')['revenue_per_net_circulation']\n",
    "                .pct_change() * 100\n",
    ")\n",
    "\n",
    "# Overall average YOY (per city, broadcast to each row)\n",
    "city_revenue['Overall_AVG_YOY(2019-2025)'] = (\n",
    "    city_revenue.groupby('city')['YOY'].transform('mean').round(2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_avg_yoy = (\n",
    "    city_revenue.groupby('city', as_index=False)['YOY']\n",
    "                .mean()\n",
    "                .rename(columns={'YOY': 'Overall_AVG_YOY(2019-2025)'})\n",
    "                .round(2)\n",
    "                .sort_values('Overall_AVG_YOY(2019-2025)', ascending=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc36797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Growth\n",
    "Positive_Growth=city_avg_yoy[city_avg_yoy['Overall_AVG_YOY(2019-2025)'] > 0]\n",
    "\n",
    "# Negetive Growth\n",
    "Negetive_Growth =city_avg_yoy[city_avg_yoy['Overall_AVG_YOY(2019-2025)'] <0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec1ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add total revenue & circulation per city for better insights\n",
    "city_summary = (\n",
    "    city_revenue.groupby('city', as_index=False)\n",
    "    .agg({\n",
    "        'ad_revenue_inr': 'sum',\n",
    "        'Net_Circulation': 'sum',\n",
    "        'Overall_AVG_YOY(2019-2025)': 'first'  # same for all rows of a city\n",
    "    })\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "fig = px.bar(\n",
    "    city_summary,\n",
    "    x='city',\n",
    "    y='Overall_AVG_YOY(2019-2025)',\n",
    "    title='Overall Average YOY (2019-2025) by City',\n",
    "    labels={'city': 'City', 'Overall_AVG_YOY(2019-2025)': 'Overall Avg YOY (%)'},\n",
    "    height=800,\n",
    "    color='Overall_AVG_YOY(2019-2025)',\n",
    "    color_continuous_scale='Turbo',\n",
    "    hover_data={\n",
    "        'ad_revenue_inr': ':.0f',\n",
    "        'Net_Circulation': ':.0f',\n",
    "        'Overall_AVG_YOY(2019-2025)': ':.2f',\n",
    "        'city': True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Layout improvements\n",
    "fig.update_layout(\n",
    "    xaxis=dict(tickangle=-45, categoryorder='total descending'),\n",
    "    yaxis=dict(title='Overall Avg YOY (%)'),\n",
    "    margin=dict(l=40, r=40, t=60, b=200),\n",
    "    coloraxis_colorbar=dict(title=\"Avg YOY (%)\")\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05113121",
   "metadata": {},
   "source": [
    "**8. How does language (Hindi vs. English) impact net circulation trends in Tier 1 vs. Tier 3 Cities** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa749181",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_req = ['city_id', 'city', 'tier', 'language', 'Net_Circulation']\n",
    "\n",
    "merged_df = (\n",
    "    pd.merge(\n",
    "        left=dim_city_df,\n",
    "        right=fact_print_sales_df,\n",
    "        left_on='city_id',\n",
    "        right_on='City_ID'\n",
    "    )[cols_req]  # keep selected columns\n",
    "    .groupby(['city', 'tier', 'language'], as_index=False)['Net_Circulation']\n",
    "    .sum()  # aggregate circulation\n",
    ")\n",
    "language_trend = merged_df\n",
    "\n",
    "language_trend_EG_HD = language_trend[\n",
    "    language_trend['language'].isin(['Hindi', 'English'])  # filter for Hindi & English\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3fe0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df_lang = language_trend_EG_HD.sort_values('Net_Circulation', ascending=False)  # sort by circulation\n",
    "\n",
    "sorted_df_lang.groupby('tier', group_keys=False).head(5)[\n",
    "    ['city', 'tier', 'language', 'Net_Circulation']\n",
    "].reset_index(drop=True)  # top 5 cities per tier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ce412",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_trend = language_trend['language'].value_counts().reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    language_trend.head(20),  \n",
    "    x=\"language\",  \n",
    "    y=\"count\",  \n",
    "    title=\"Distribution of Languages by Count\",  \n",
    "    labels={\"language\": \"Language\", \"count\": \"Total Count\"},  \n",
    "    text=\"count\",  # show values on bars\n",
    "    color=\"count\",  # distinct colors per language\n",
    "    height=600,\n",
    "    color_continuous_scale='Turbo'\n",
    ")\n",
    "\n",
    "# Beautify\n",
    "fig.update_traces(\n",
    "    texttemplate='%{text:,}',  # format numbers with commas\n",
    "    textposition='outside'\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Language\",\n",
    "    yaxis_title=\"Count\",\n",
    "    uniformtext_minsize=10,\n",
    "    uniformtext_mode='hide',\n",
    "    plot_bgcolor=\"white\",\n",
    "    bargap=0.3,\n",
    "    title_x=0.5,  # center title\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314dfd7b",
   "metadata": {},
   "source": [
    "**9. What is the correlation between internet penetration and ad revenue from \n",
    "commercial categories like FMCG?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b34433",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = fact_city_readiness_df.copy()  # copy readiness data\n",
    "temp_data['city_id_temp'] = 'ED1' + temp_data['city_id'].astype(str)\n",
    "temp_data['ED_city_id'] = temp_data['city_id_temp'].str.split('C').str[0] + temp_data['city_id_temp'].str.split('C').str[1]\n",
    "\n",
    "# merge ad revenue, category info, readiness data, and city details\n",
    "commercial_cat_rev = pd.merge(\n",
    "    cat_revenue, dim_ad_category_df, left_on='ad_category', right_on='ad_category_id'\n",
    ")[['edition_id', 'ad_category', 'category_group', 'ad_revenue_inr', 'Year']].merge(\n",
    "    temp_data, left_on='edition_id', right_on='ED_city_id'\n",
    ")[['city_id', 'ad_category', 'category_group', 'ad_revenue_inr', 'Year', 'internet_penetration']].merge(\n",
    "    dim_city_df, left_on='city_id', right_on='city_id'\n",
    ")[['city', 'category_group', 'ad_revenue_inr', 'Year', 'internet_penetration']]\n",
    "\n",
    "# filter for commercial brands and aggregate\n",
    "commercial_cat_rev = commercial_cat_rev[commercial_cat_rev['category_group'] == 'Commercial Brands']\n",
    "commercial_cat_rev = commercial_cat_rev.groupby('city').agg({\n",
    "    'ad_revenue_inr': 'sum',\n",
    "    'internet_penetration': 'mean'\n",
    "}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d52c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13d8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = commercial_cat_rev['ad_revenue_inr'].corr(commercial_cat_rev['internet_penetration'])\n",
    "print(f\"Correlation between ad revenue and internet penetration: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1edca4",
   "metadata": {},
   "source": [
    "**10. Which states show the highest year-over-year growth in literacy rates, and how does \n",
    "this align with digital pilot success?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge city, readiness, and digital pilot data\n",
    "literacy_rate_yoy = pd.merge(dim_city_df, fact_city_readiness_df, on='city_id')[\n",
    "    ['city_id', 'city', 'state', 'quarter', 'literacy_rate']\n",
    "].merge(\n",
    "    fact_digital_pilot_df, left_on='city_id', right_on='city_id'\n",
    ")[['city_id', 'city', 'state', 'quarter', 'literacy_rate', 'users_reached']]\n",
    "\n",
    "# extract year from quarter\n",
    "literacy_rate_yoy['Year'] = literacy_rate_yoy['quarter'].str.split('-').str[0]\n",
    "\n",
    "# aggregate literacy rate and users reached by city & year\n",
    "literacy_rate_yoy = literacy_rate_yoy.groupby(['city', 'Year']).agg({\n",
    "    'literacy_rate': 'mean',\n",
    "    'users_reached': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# calculate YoY change in literacy rate\n",
    "literacy_rate_yoy['YOY'] = (\n",
    "    literacy_rate_yoy.groupby('city')['literacy_rate'].pct_change() * 100\n",
    ").fillna(0).round(2)\n",
    "\n",
    "# get top cities with highest YoY literacy growth\n",
    "top_growth = (\n",
    "    literacy_rate_yoy.groupby('city')['YOY']\n",
    "    .max()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={'YOY': 'max_YOY_growth'})\n",
    ")\n",
    "\n",
    "top_growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a272277",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    top_growth.head(20),\n",
    "    x=\"city\",\n",
    "    y=\"max_YOY_growth\",\n",
    "    color=\"max_YOY_growth\",  # color scale based on growth\n",
    "    title=\"Top YoY Literacy Rate Growth by City\",\n",
    "    labels={\"city\": \"City\", \"max_YOY_growth\": \"Max YoY Literacy Rate Growth (%)\"},\n",
    "    height=700,\n",
    "    color_continuous_scale=\"Viridis\"  # you can try \"Plasma\", \"Cividis\", etc.\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45,\n",
    "    plot_bgcolor=\"white\",\n",
    "    yaxis=dict(showgrid=True, gridcolor=\"lightgrey\"),\n",
    "    font=dict(size=12),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a27ed",
   "metadata": {},
   "source": [
    "#### **11. How has the average bounce rate in digital pilots varied by platform (e.g., WhatsApp vs. Mobile App)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_digital_pilot_df.groupby('platform')['avg_bounce_rate'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52000d0a",
   "metadata": {},
   "source": [
    "#### **12. What is the impact of marketing costs on users reached in digital pilots across different ad categories?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481adcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_cost = fact_digital_pilot_df.groupby('ad_category_id').agg({\n",
    "    'marketing_cost' : 'sum',\n",
    "    'users_reached'  : 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b97d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between marketing cost and users reached\n",
    "correlation = mark_cost['marketing_cost'].corr(mark_cost['users_reached'])\n",
    "print(\"Correlation:\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137f6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    mark_cost,\n",
    "    x='marketing_cost',\n",
    "    y='users_reached',\n",
    "    trendline='ols',\n",
    "    title='Marketing Cost Vs User Reached',\n",
    "    labels={\n",
    "        'marketing_cost' : \"Marketing Cost\",\n",
    "        'users_reached'  : 'User Reached'\n",
    "    },\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=10, color='royalblue', line=dict(width=1, color='DarkSlateGrey')))\n",
    "fig.update_layout(title_font_size=20, title_x=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af1b63",
   "metadata": {},
   "source": [
    "#### **13. What trends emerge in dev_cost vs. downloads_or_accesses for digital pilots in Tier 3 cities?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge city and digital pilot data\n",
    "dev_mark_cost = pd.merge(\n",
    "    dim_city_df, fact_digital_pilot_df, on='city_id'\n",
    ")[['ad_category_id', 'tier', 'platform', 'dev_cost', 'downloads_or_accesses']]\n",
    "\n",
    "# filter for Tier 3 cities\n",
    "dev_mark_cost = dev_mark_cost[dev_mark_cost['tier'] == 'Tier 3']\n",
    "\n",
    "# aggregate total dev cost and downloads by ad category\n",
    "dev_mark_cost = fact_digital_pilot_df.groupby('ad_category_id').agg({\n",
    "    'dev_cost': 'sum',\n",
    "    'downloads_or_accesses': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# compute correlation between dev cost and downloads\n",
    "dev_mark_cost['dev_cost'].corr(dev_mark_cost['downloads_or_accesses'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c397b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    dev_mark_cost,\n",
    "    x='dev_cost',\n",
    "    y='downloads_or_accesses',\n",
    "    trendline='ols',\n",
    "    title='Marketing Cost Vs User Reached',\n",
    "    labels={\n",
    "        'dev_cost' : \"Development Cost\",\n",
    "        'downloads_or_accesses'  : 'Downloads or Accesses'\n",
    "    },\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=10, color='royalblue', line=dict(width=1, color='DarkSlateGrey')))\n",
    "fig.update_layout(title_font_size=20, title_x=0.5)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1714b1",
   "metadata": {},
   "source": [
    "#### **14. How do ad revenue comments (e.g., \"Festive push\") correlate with quarterly spikes in specific categories?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e70fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter festive push data and aggregate ad revenue by category & quarter\n",
    "qtr_spike_df = (\n",
    "    fact_ad_revenue_df[fact_ad_revenue_df['comments'] == 'Festive push']\n",
    "    .groupby(['ad_category', 'quarter'])['ad_revenue']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "qtr_spike_df['ad_revenue'] = qtr_spike_df['ad_revenue'].astype(int)  # ensure integer type\n",
    "\n",
    "# calculate YoY growth in festive quarter revenue by ad category\n",
    "qtr_spike_df['qtr_spike_YOY_growth'] = (\n",
    "    qtr_spike_df.groupby('ad_category')['ad_revenue']\n",
    "    .pct_change()\n",
    "    .fillna(0) * 100\n",
    ").round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    qtr_spike_df,\n",
    "    x=\"quarter\",\n",
    "    y=\"ad_revenue\",\n",
    "    color=\"ad_category\",\n",
    "    markers=True,\n",
    "    title=\"Quarterly Ad Revenue Spikes during Festive Push\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=-45,\n",
    "    yaxis_title=\"Ad Revenue\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f79f56",
   "metadata": {},
   "source": [
    "**15. Which example brands in ad categories appear most frequently in high-revenue quarters?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1437081",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ad_category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = qtr_spike_df['ad_revenue'].quantile(0.75)\n",
    "\n",
    "# Step 2: Filter high-revenue quarters\n",
    "high_revenue_df = qtr_spike_df[qtr_spike_df['ad_revenue'] > threshold]\n",
    "\n",
    "# Step 3: Count high-revenue quarters per ad_category\n",
    "high_revenue_counts = high_revenue_df['ad_category'].value_counts().reset_index()\n",
    "high_revenue_counts.columns = ['ad_category', 'high_revenue_quarter_count']\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Plot using Plotly\n",
    "fig = px.bar(\n",
    "    high_revenue_counts,\n",
    "    x='ad_category',\n",
    "    y='high_revenue_quarter_count',\n",
    "    title='High-Revenue Quarters per Ad Category',\n",
    "    labels={'high_revenue_quarter_count': 'Count of High-Revenue Quarters', 'ad_category': 'Ad Category'},\n",
    "    color='ad_category'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4475af0c",
   "metadata": {},
   "source": [
    "**16. What is the year-over-year (YoY) growth in net circulation for print sales by state and language?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yoy_growth_by_nc = pd.merge(\n",
    "    dim_city_df ,fact_print_sales_df , left_on='city_id' , right_on='City_ID'\n",
    "    )[['city_id' ,'date', 'city' , 'state','Language','Net_Circulation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0916e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from date column\n",
    "yoy_growth_by_nc['Year'] = yoy_growth_by_nc['date'].dt.year\n",
    "\n",
    "# Group by city, Language, and Year to get yearly totals\n",
    "yearly_circulation = (\n",
    "    yoy_growth_by_nc.groupby(['city', 'Language', 'Year'])['Net_Circulation']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Sort values for proper growth calculation\n",
    "yearly_circulation = yearly_circulation.sort_values(by=['city', 'Language', 'Year'])\n",
    "\n",
    "# Calculate year-over-year growth (%)\n",
    "yearly_circulation['Growth(%)'] = (\n",
    "    yearly_circulation.groupby(['city', 'Language'])['Net_Circulation']\n",
    "    .pct_change()\n",
    "    .fillna(0) * 100\n",
    ")\n",
    "\n",
    "# Optional: Round for readability\n",
    "yearly_circulation['Growth(%)'] = yearly_circulation['Growth(%)'].round(2)\n",
    "yearly_circulation.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6925d",
   "metadata": {},
   "source": [
    "**17. How does the average quarterly ad revenue per edition compare across currencies (INR, USD, EUR), after standardizing to INR?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average ad revenue by edition, quarter, and currency\n",
    "avg_ad_rev_by_curr = fact_ad_revenue_df.groupby(\n",
    "    ['edition_id', 'quarter', 'currency']\n",
    ")['ad_revenue'].mean().reset_index()\n",
    "\n",
    "avg_ad_rev_by_curr['ad_revenue'] = avg_ad_rev_by_curr['ad_revenue'].astype(int)  # convert to int\n",
    "\n",
    "# convert revenue to INR using approximate exchange rates\n",
    "avg_ad_rev_by_curr['ad_revenue_in_inr'] = avg_ad_rev_by_curr.apply(\n",
    "    lambda row: row['ad_revenue'] * 85 if row['currency'] == 'USD'\n",
    "    else row['ad_revenue'] * 100 if row['currency'] == 'EUR'\n",
    "    else row['ad_revenue'],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f194c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    avg_ad_rev_by_curr,  # your dataframe\n",
    "    x='quarter',\n",
    "    y='ad_revenue_in_inr',\n",
    "    color='currency',  # optional: separate boxes by currency\n",
    "    title='Distribution of Ad Revenue (INR) by Quarter and Currency',\n",
    "    labels={\n",
    "        'quarter': 'Quarter',\n",
    "        'ad_revenue_in_inr': 'Ad Revenue (in INR)',\n",
    "        'currency': 'Currency'\n",
    "    },\n",
    "    points='outliers'  # show outlier points\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    boxmode='group',\n",
    "    template='plotly_dark',  # or 'plotly_white' if you prefer light theme\n",
    "    title_x=0.5,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fd7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average ad revenue per quarter and currency\n",
    "trend_df = (\n",
    "    avg_ad_rev_by_curr.groupby(['quarter', 'currency'])['ad_revenue_in_inr']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig_trend = px.line(\n",
    "    trend_df,\n",
    "    x='quarter',\n",
    "    y='ad_revenue_in_inr',\n",
    "    color='currency',\n",
    "    markers=True,\n",
    "    title='Ad Revenue Trend Over Quarters (in INR)',\n",
    "    labels={\n",
    "        'quarter': 'Quarter',\n",
    "        'ad_revenue_in_inr': 'Average Ad Revenue (INR)',\n",
    "        'currency': 'Currency'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig_trend.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title_x=0.5,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_trend.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae6d47",
   "metadata": {},
   "source": [
    "#### **18. Do cities with high literacy rates show lower average bounce rates in digital pilots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36642f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge digital pilot, readiness, and city data\n",
    "literacy_rate = pd.merge(\n",
    "    fact_digital_pilot_df, fact_city_readiness_df, on='city_id'\n",
    ")[['city_id', 'quarter', 'literacy_rate', 'avg_bounce_rate']].merge(\n",
    "    dim_city_df, on='city_id'\n",
    ")[['city', 'literacy_rate', 'avg_bounce_rate']]\n",
    "\n",
    "# compute average literacy and bounce rate per city\n",
    "literacy_rate = literacy_rate.groupby('city').agg({\n",
    "    'literacy_rate': 'mean',\n",
    "    'avg_bounce_rate': 'mean'\n",
    "}).reset_index().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds for high literacy and low bounce rate\n",
    "high_literacy_rate_thrashold = literacy_rate['literacy_rate'].quantile(0.75)\n",
    "lower_avg_bounce_rate_thrashold = literacy_rate['avg_bounce_rate'].quantile(0.25)\n",
    "\n",
    "# filter cities based on thresholds\n",
    "hight_literacy_rate_cities = literacy_rate[literacy_rate['literacy_rate'] >= high_literacy_rate_thrashold]\n",
    "low_bounce_rate_cities = literacy_rate[literacy_rate['avg_bounce_rate'] <= lower_avg_bounce_rate_thrashold]\n",
    "\n",
    "# get cities with both high literacy and low bounce rate\n",
    "hight_literacy_rate_cities_list = hight_literacy_rate_cities['city'].to_list()\n",
    "high_literacy_low_bounceRate = low_bounce_rate_cities[low_bounce_rate_cities['city'].isin(hight_literacy_rate_cities_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = high_literacy_low_bounceRate['literacy_rate'].corr(\n",
    "    high_literacy_low_bounceRate['avg_bounce_rate']\n",
    ")\n",
    "print(f\"Correlation between Literacy Rate and Average Bounce Rate: {correlation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(\n",
    "    high_literacy_low_bounceRate.melt(id_vars='city', \n",
    "                                      value_vars=['literacy_rate', 'avg_bounce_rate'], \n",
    "                                      var_name='Metric', \n",
    "                                      value_name='Value'),\n",
    "    x='Metric',\n",
    "    y='Value',\n",
    "    box=True,  # adds box inside the violin for median & quartiles\n",
    "    points='all',  # show all points for transparency\n",
    "    title='Distribution of Literacy Rate and Average Bounce Rate',\n",
    "    color='Metric'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',   # modern dark theme\n",
    "    title_x=0.5,\n",
    "    height=600,\n",
    "    yaxis_title='Value',\n",
    "    xaxis_title='Metric'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e9b7d6",
   "metadata": {},
   "source": [
    "#### **19. Which states show the biggest gap between internet penetration and actual downloads_or_accesses in digital pilots?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52436b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "internePenetration_vs_act_downloads = pd.merge(\n",
    "    fact_digital_pilot_df , fact_city_readiness_df , on='city_id'\n",
    "    )[['city_id','downloads_or_accesses','internet_penetration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate thresholds\n",
    "high_internet_pen_threshold = internePenetration_vs_act_downloads['internet_penetration'].quantile(0.75)\n",
    "low_internet_pen_threshold = internePenetration_vs_act_downloads['internet_penetration'].quantile(0.25)\n",
    "\n",
    "high_downloads_threshold = internePenetration_vs_act_downloads['downloads_or_accesses'].quantile(0.75)\n",
    "low_downloads_threshold = internePenetration_vs_act_downloads['downloads_or_accesses'].quantile(0.25)\n",
    "\n",
    "# 1️⃣ High Internet Penetration but Low Downloads\n",
    "high_pen_low_downloads = internePenetration_vs_act_downloads[\n",
    "    (internePenetration_vs_act_downloads['internet_penetration'] >= high_internet_pen_threshold) &\n",
    "    (internePenetration_vs_act_downloads['downloads_or_accesses'] <= low_downloads_threshold)\n",
    "]\n",
    "\n",
    "# 2️⃣ Low Internet Penetration but High Downloads\n",
    "low_pen_high_downloads = internePenetration_vs_act_downloads[\n",
    "    (internePenetration_vs_act_downloads['internet_penetration'] <= low_internet_pen_threshold) &\n",
    "    (internePenetration_vs_act_downloads['downloads_or_accesses'] >= high_downloads_threshold)\n",
    "]\n",
    "\n",
    "# Display insights\n",
    "print(\"Cities with High Internet Penetration but Low Downloads:\", len(high_pen_low_downloads))\n",
    "print(\"Cities with Low Internet Penetration but High Downloads:\", len(low_pen_high_downloads))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44231554",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    internePenetration_vs_act_downloads,\n",
    "    x='internet_penetration',\n",
    "    y='downloads_or_accesses',\n",
    "    title='Internet Penetration vs App Downloads/Accesses',\n",
    "    labels={\n",
    "        'internet_penetration': 'Internet Penetration (%)',\n",
    "        'downloads_or_accesses': 'App Downloads or Accesses'\n",
    "    },\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "# Add threshold lines\n",
    "fig.add_vline(x=high_internet_pen_threshold, line_dash=\"dash\", line_color=\"green\", annotation_text=\"High Penetration Threshold\")\n",
    "fig.add_vline(x=low_internet_pen_threshold, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Low Penetration Threshold\")\n",
    "fig.add_hline(y=high_downloads_threshold, line_dash=\"dash\", line_color=\"blue\", annotation_text=\"High Downloads Threshold\")\n",
    "fig.add_hline(y=low_downloads_threshold, line_dash=\"dash\", line_color=\"orange\", annotation_text=\"Low Downloads Threshold\")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title_x=0.5,\n",
    "    height=700\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b1be6",
   "metadata": {},
   "source": [
    "#### **20. What is the overall transition index (digital users reached / print net circulation) by city, and how has it evolved YoY?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge fact_digital_pilot_df and fact_print_sales_df\n",
    "transition_index = (\n",
    "    pd.merge(\n",
    "        fact_digital_pilot_df,\n",
    "        fact_print_sales_df,\n",
    "        left_on='city_id',\n",
    "        right_on='City_ID'\n",
    "    )[['City_ID', 'date', 'Net_Circulation', 'users_reached']]\n",
    "    .merge(\n",
    "        dim_city_df,\n",
    "        left_on='City_ID',\n",
    "        right_on='city_id'\n",
    "    )[['city', 'date', 'Net_Circulation', 'users_reached']]\n",
    ")\n",
    "\n",
    "# Step 2: Convert date to year\n",
    "transition_index['date'] = transition_index['date'].dt.year\n",
    "\n",
    "# Step 3: Aggregate data by city and year\n",
    "transition_index = (\n",
    "    transition_index\n",
    "    .groupby(['city', 'date'], as_index=False)\n",
    "    .agg({\n",
    "        'Net_Circulation': 'sum',\n",
    "        'users_reached': 'sum'\n",
    "    })\n",
    ")\n",
    "\n",
    "# Step 4: Calculate Transition Index (%)\n",
    "transition_index['transition_index'] = (\n",
    "    (transition_index['users_reached'] / transition_index['Net_Circulation']) * 100\n",
    ").round(2)\n",
    "\n",
    "# Step 5: Calculate YoY growth of Transition Index\n",
    "transition_index['YOY_growth_transition_index'] = (\n",
    "    transition_index\n",
    "    .sort_values(['city', 'date'])\n",
    "    .groupby('city')['transition_index']\n",
    "    .pct_change() * 100\n",
    ").round(2).fillna(0)\n",
    "\n",
    "# Final output\n",
    "transition_index.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ff480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Prepare data ---\n",
    "transition_index = transition_index.sort_values(['city', 'date'])\n",
    "\n",
    "# Select top 50 cities based on average Transition Index\n",
    "top_50_cities = (\n",
    "    transition_index.groupby('city')['transition_index']\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(50)\n",
    "    .index\n",
    ")\n",
    "\n",
    "top_50_data = transition_index[transition_index['city'].isin(top_50_cities)]\n",
    "\n",
    "# --- Step 2: Define subplot layout ---\n",
    "rows = 10\n",
    "cols = 5\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 30), sharex=True, sharey=True)\n",
    "\n",
    "# Flatten axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# --- Step 3: Plot each city ---\n",
    "for i, city in enumerate(top_50_cities):\n",
    "    ax = axes[i]\n",
    "    city_data = top_50_data[top_50_data['city'] == city]\n",
    "    \n",
    "    ax.plot(city_data['date'], city_data['transition_index'], marker='o', linewidth=1.8)\n",
    "    ax.set_title(city, fontsize=9)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Optional: Add YOY growth line on secondary y-axis\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(city_data['date'], city_data['YOY_growth_transition_index'], color='orange', linestyle='--', linewidth=1)\n",
    "    ax2.set_yticks([])\n",
    "\n",
    "# --- Step 4: Adjust layout ---\n",
    "fig.suptitle('Transition Index Trends & YoY Growth (Top 50 Cities)', fontsize=18, fontweight='bold')\n",
    "fig.text(0.5, 0.04, 'Year', ha='center', fontsize=12)\n",
    "fig.text(0.04, 0.5, 'Transition Index (%)', va='center', rotation='vertical', fontsize=12)\n",
    "plt.tight_layout(rect=[0.03, 0.05, 1, 0.96])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
